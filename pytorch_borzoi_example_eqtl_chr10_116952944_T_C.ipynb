{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f5cddc-2bac-4c5b-8e65-73475b890058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyfaidx\n",
    "import json\n",
    "import pysam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "from tqdm import tqdm\n",
    "from pytorch_borzoi import Borzoi\n",
    "from pytorch_borzoi_helpers import predict_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e8688-635e-435b-b68d-c20f3a9af874",
   "metadata": {},
   "source": [
    "#### We check if all tracks of the WT sequence of the EQTL example are predicted with the Pytorch model as with the original Calico TF keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00068a0e-3a1e-48fa-990f-824a2f9b49b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "folds = 4\n",
    "model_folds = []\n",
    "for fold in tqdm(range(folds)):\n",
    "    borzoi = Borzoi(checkpoint_path = f'pytorch_weights/borzoi_fold{fold}.pt')\n",
    "    borzoi.to(device)\n",
    "    borzoi.eval()\n",
    "    model_folds.append(borzoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6eda576-6ef0-4144-929c-0dd40530473b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slices = [7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532,\n",
    "            7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543,\n",
    "            7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554,\n",
    "            7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565,\n",
    "            7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576,\n",
    "            7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587,\n",
    "            7588, 7589, 7590, 7591, 7592, 7593, 7594, 7595, 7596, 7597, 7598,\n",
    "            7599, 7600, 7601, 7602, 7603, 7604, 7605, 7606, 7607, 7608, 7609,\n",
    "            7610] # slices from the first EQTL example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182dfa80-cbf9-46ed-bd0b-1701db071f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequence_one_hot_wt = torch.as_tensor(np.load('../wt_seq.npy')).to(device)\n",
    "wt_pred_across_folds_pt = predict_tracks(model_folds,sequence_one_hot_wt.permute(1,0), slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab9c8f2-cf54-434c-a280-74056c069242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wt_pred_across_folds_tf = np.load('../wt_pred_across_folds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f3f8a2-9cc8-4537-b596-afe0d182e673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4, 16352, 89), (1, 4, 16352, 89))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_pred_across_folds_pt.shape, wt_pred_across_folds_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8be096f-0484-4688-b00a-f5a6e05e7429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(wt_pred_across_folds_pt,wt_pred_across_folds_tf,rtol=0, atol = 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20b8a9-f09e-4fd6-b3fe-903c298fedd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Up to numerical precision, the Borzoi-ensemble ported to Pytorch gets the same results as the TF-Borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c403f23-98e4-46e0-8f3d-6992d7b164c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.6815963, 4.6815977)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_pred_across_folds_pt.max(), wt_pred_across_folds_tf.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a557f5ca-4313-41b8-9416-cd988baa525a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0989912e-07, 4.099e-07)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_pred_across_folds_pt.min(), wt_pred_across_folds_tf.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4640e-c5ff-4501-8888-232a9c290ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-pytorch_enformer]",
   "language": "python",
   "name": "conda-env-anaconda-pytorch_enformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
